"""
Commit 25: Explainability & Vulnerability Mapping

Maps ML risk predictions to human-readable vulnerability areas.
Explains WHY each claim is risky and what interview questions could probe it.
"""

from typing import List, Dict
from ml.feature_builder import build_feature_vector
from nlp.keyword_extractor import extractor


# =========================================================
# Vulnerability Categories
# =========================================================

VULNERABILITY_RULES = {
    "no_metrics": {
        "check": lambda f: f.get("clarity_has_metrics", 0) == 0,
        "label": "No Quantified Impact",
        "description": "Claim lacks numbers, percentages, or measurable outcomes",
        "interview_angle": "Ask: 'Can you quantify the impact of this work?'",
        "severity": "high",
    },
    "weak_language": {
        "check": lambda f: f.get("quant_has_weak_language", 0) == 1,
        "label": "Vague/Passive Language",
        "description": "Uses phrases like 'responsible for', 'helped with', 'involved in'",
        "interview_angle": "Ask: 'What specifically was YOUR contribution here?'",
        "severity": "high",
    },
    "no_action_verb": {
        "check": lambda f: f.get("clarity_has_action_verb", 0) == 0,
        "label": "Missing Action Verb",
        "description": "Doesn't start with an action verb — unclear what was done",
        "interview_angle": "Ask: 'Walk me through what you actually built or did.'",
        "severity": "medium",
    },
    "no_tech_keywords": {
        "check": lambda f: f.get("sem_num_keywords", 0) == 0,
        "label": "No Technical Specifics",
        "description": "Claim mentions no specific technologies, tools, or frameworks",
        "interview_angle": "Ask: 'What technologies/tools did you use for this?'",
        "severity": "medium",
    },
    "too_short": {
        "check": lambda f: f.get("txt_word_count", 0) < 8,
        "label": "Insufficient Detail",
        "description": "Claim is too brief to convey meaningful information",
        "interview_angle": "Ask: 'Can you elaborate on the scope and complexity?'",
        "severity": "low",
    },
    "buzzword_heavy": {
        "check": lambda f: (
            f.get("sem_num_keywords", 0) >= 4 and
            f.get("clarity_has_metrics", 0) == 0 and
            f.get("quant_number_count", 0) == 0
        ),
        "label": "Buzzword Stacking",
        "description": "Lists many technologies but no evidence of depth",
        "interview_angle": "Ask: 'Pick one of these technologies — explain a problem you solved with it.'",
        "severity": "high",
    },
}


def analyze_claim_vulnerabilities(claim: dict, risk_result: dict) -> dict:
    """
    Analyze a single claim for vulnerabilities.

    Args:
        claim: {"text": ..., "section": ...}
        risk_result: output from RiskClassifier.predict()

    Returns:
        Per-claim vulnerability analysis with explanations.
    """
    features = build_feature_vector(claim)
    vulnerabilities = []

    for rule_id, rule in VULNERABILITY_RULES.items():
        if rule["check"](features):
            vulnerabilities.append({
                "id": rule_id,
                "label": rule["label"],
                "description": rule["description"],
                "interview_angle": rule["interview_angle"],
                "severity": rule["severity"],
            })

    # Sort by severity
    severity_order = {"high": 0, "medium": 1, "low": 2}
    vulnerabilities.sort(key=lambda v: severity_order.get(v["severity"], 3))

    return {
        "text": claim["text"],
        "section": claim.get("section", ""),
        "risk_label": risk_result["risk_label"],
        "risk_score": risk_result["risk_score"],
        "vulnerabilities": vulnerabilities,
        "vulnerability_count": len(vulnerabilities),
        "is_strong": len(vulnerabilities) == 0 and risk_result["risk_score"] < 25,
    }


def map_resume_vulnerabilities(
    claims: list[dict],
    risk_classifier,
) -> dict:
    """
    Full resume vulnerability analysis.

    Returns:
        - per_claim: detailed per-claim breakdown
        - summary: aggregated vulnerability stats
        - top_vulnerabilities: most common weakness areas
        - strengths: claims that passed all checks
        - interview_focus_areas: recommended areas to probe
    """

    per_claim = []
    vuln_counts: dict = {}
    strengths = []
    weaknesses = []

    for claim in claims:
        features = build_feature_vector(claim)
        risk = risk_classifier.predict(features)
        analysis = analyze_claim_vulnerabilities(claim, risk)
        per_claim.append(analysis)

        # aggregate
        for v in analysis["vulnerabilities"]:
            vid = v["id"]
            vuln_counts[vid] = vuln_counts.get(vid, 0) + 1

        if analysis["is_strong"]:
            strengths.append(claim["text"])
        elif analysis["vulnerability_count"] >= 2:
            weaknesses.append(claim["text"])

    # rank vulnerabilities by frequency
    top_vulns = sorted(vuln_counts.items(), key=lambda x: x[1], reverse=True)
    top_vulns = [
        {
            "id": vid,
            "label": VULNERABILITY_RULES[vid]["label"],
            "count": count,
            "percentage": round(count / len(claims) * 100, 1),
        }
        for vid, count in top_vulns
    ]

    # interview focus = top 3 vulnerabilities with interview angles
    interview_focus = []
    for v in top_vulns[:3]:
        rule = VULNERABILITY_RULES[v["id"]]
        interview_focus.append({
            "area": rule["label"],
            "probe": rule["interview_angle"],
            "affected_claims": v["count"],
        })

    return {
        "per_claim": per_claim,
        "summary": {
            "total_claims": len(claims),
            "strong_claims": len(strengths),
            "weak_claims": len(weaknesses),
            "strength_ratio": round(len(strengths) / max(len(claims), 1) * 100, 1),
        },
        "top_vulnerabilities": top_vulns,
        "strengths": strengths,
        "weaknesses": weaknesses,
        "interview_focus_areas": interview_focus,
    }
